% 波-粒（局部连接）二象性
% 波和连接同时考虑比单独一个精度更高
% 全局的波在局部形成共振

% Alex --> 神经场理论中的深度学习 -> 几何约束
% https://github.com/kwignb/RandomNeuralField/blob/main/src/models/networks.py

% 神经场介绍
%Version 3 October 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove Numbered in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst%  
 
%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


% 需要将bst目录下的sn-mathphys-num.bst复制到根目录下，否则参考文献为问号
\documentclass[sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style 
%%\documentclass[sn-mathphys-ay]{sn-jnl}% Math and Physical Sciences Author Year Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
%%%%

\usepackage{subfigure}  % 使用子图（多个图凑九宫格）

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

%\bibliography{reference}

\begin{document}

% Geometric constraints on human brain function
% Structure constraints human brain function and artificial neural network
\title[Article Title]{Whole-body physics simulation of human locomotion}
% Structure Bias in Artificial Neural Network

%%=============================================================%%
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% \author*[1,2]{\fnm{Joergen W.} \spfx{van der} \sur{Ploeg} 
%%  \sfx{IV}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1,2]{\fnm{First} \sur{Author}}\email{iauthor@gmail.com}

\author[2,3]{\fnm{Second} \sur{Author}}\email{iiauthor@gmail.com}
\equalcont{These authors contributed equally to this work.}

\author[1,2]{\fnm{Third} \sur{Author}}\email{iiiauthor@gmail.com}
\equalcont{These authors contributed equally to this work.}

\affil*[1]{\orgdiv{Department}, \orgname{Organization}, \orgaddress{\street{Street}, \city{City}, \postcode{100190}, \state{State}, \country{Country}}}

\affil[2]{\orgdiv{Department}, \orgname{Organization}, \orgaddress{\street{Street}, \city{City}, \postcode{10587}, \state{State}, \country{Country}}}

%\affil[3]{\orgdiv{Department}, \orgname{Organization}, \orgaddress{\street{Street}, \city{City}, \postcode{610101}, \state{State}, \country{Country}}}

%%==================================%%
%% Sample for unstructured abstract %%
%%==================================%%

\abstract{
	% 出发点：身体 影响 神经系统生成行为
	The body of an human infuences how its nervous system generates behaviour\cite{dickinson2000animals}. 
	% 建模的重要性：感觉运动需要
	Accurately modelling the neural control of sensorimotor behaviour requires an anatomically detailed biomechanical representation of the body. 
	Here we introduce a whole-body model of the human in a physics simulator. 
	Designed as a general-purpose framework, our model enables the simulation of diverse movement behaviours, including both walking and running locomotion. 
	We validate its versatility by replicating realistic walking and running behaviours. 
	To support these behaviours, we develop phenomenological models for fuid and adhesion forces. 
	Using data-driven, end-to-end reinforcement learning\cite{peng2018deepmimic,hasenclever2020comic}, we train neural network controllers capable of generating naturalistic locomotion\cite{muijres2014flies,muijres2015body,deangelis2019manifold} along complex trajectories in response to high-level steering commands. 
	Furthermore, we show the use of visual sensors and hierarchical motor control\cite{merel2019hierarchical}, training a high-level controller to reuse a pretrained low-level fight controller to perform visually guided walking tasks. 
	Our model serves as an open-source platform for studying the neural control of sensorimotor behaviour in an embodied context.
}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

%\keywords{Whole-body physics simulation of human locomotion}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

% 识别人脸的人工神经网络如何用波动力学解释
\section{Introduction}\label{sec1}

% 大脑、身体、环境 -> (感觉运行循环) -> 行为
Human behaviour emerges from sensorimotor feedback loops that integrate signals from the brain, body and environment\cite{dickinson2000animals,peng2018deepmimic,hasenclever2020comic,muijres2014flies,muijres2015body,deangelis2019manifold,merel2019hierarchical,todorov2012mujoco}.
% 神经运动命令 -> （身体） -> 移动  -> （感觉反馈）
The body determines how neural motor commands translate into movement and how sensory feedback is generated in response. 
Therefore, a detailed biomechanical understanding of the body is crucial for modelling the neural control of movement.
Here we introduce a physics-based simulation framwork for an anatomically detailed model of the human Dong, designed to supported the modelling of diverse sensorimotor behaviours.
% 通过 RL 来演示行走和跑步
We validate our model by demonstrating realistic locomotion—both walking and running—using reinforcement learning (RL). 
This general-purpose simulation provides a platform for future studies of brain–body interactions across a broad range of human behaviours.


% 基于的其他相关工作
% 蠕虫、水螅
Our work follows previous physics-based models of the worm\cite{boyle2012gait}, hydra\cite{wang2023complete}, rodent\cite{merel2019deep} and fruit fly\cite{reiser2004vision,dickson2008integrative,lobato2022neuromechfly,wang2023neuromechfly,melis2024machine}. 
The Grand Unified Fly\cite{dickson2008integrative} pioneered sensorimotor closed-loop visually guided flight using a simplified body model and hand-designed controller. 
More recent work has revealed the basis of muscle actuation of the wing hinge\cite{melis2024machine}. 
In parallel, NeuroMechFly\cite{lobato2022neuromechfly,wang2023neuromechfly} introduced an anatomically detailed fruit fly model capable of walking and grooming, pairing a heuristically designed low-level walking controller with a learnt high-level controller to generate sensory-guided behaviours\cite{wang2023neuromechfly}.


% 自己的建模方法
Our work unifies running and walking in a single physics-based model, enhancing realism in body mechanics, physics interactions and control. 
We developed an anatomically detailed fly body model in the open-source PhysX physics engine, incorporating high-resolution imaging to reconstruct a male Dong (Fig.~\ref{fig:fig_1}). 
To accurately simulate both walking and running, we introduced a computationally efficient phenomenological fluid dynamics model to approximate aerodynamic forces from wing flapping and adhesion actuators to model foot–surface interactions.


Using high-speed kinematic tracking\cite{branson2009high,pereira2022sleap}, we trained closed-loop RL controllers capable of replicating naturalistic running movements. 
These controllers, trained for both walking (Fig.~\ref{fig:fig_2}) and running (Fig.~\ref{fig:fig_3}), operate using only high-level steering commands. 
Finally, we demonstrate the reuse of a pretrained low-level flight controller for vision-guided flight tasks (Fig.~\ref{fig:fig_4}). 
% 其他的动作：搬箱子
Through inverse kinematics, we further show that our model supports a broad behavioural repertoire beyond locomotion, including lifting a box.



%\section{Results}\label{sec2}
%
%Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text.

\section{Results}\label{sec3}

		

\subsection{Body model geometry}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=1.0\textwidth]{fig/fig_1.pdf}
	\caption{
		\textbf{Constructing the male human body model.
		}
		\textbf{(a)} Compilation of six parts representing a single human. 
		% 带腹部的胸部
		Maximum intensity projections of confocal stacks showing head, thorax with abdomen, wings and legs. 
		Scale bar, 1 mm.
		% 共焦的体积 confocal volume
		% 低多边形 网格
		% 高多边形 网格
		% 关节
		% femur: 大腿骨
		% tibia: 胫节
		% tarsal: 跗骨
		% TODO: 人腿的共焦体积的投影、
		% 高多边形 体积的3D网格（离线仿真）
		% 低多边形 体积的3D网格（实时仿真）https://zh.wikipedia.org/wiki/%E4%BD%8E%E5%A4%9A%E8%BE%B9%E5%BD%A2
		\textbf{(b)} Left, a partial projection of the midleg confocal volume with the joints between the femur, tibia and tarsal segments indicated. 
		Middle, a 3D mesh extracted from the volume. 
		Right, a low-polygon leg model. 
		Scale bar, 0.2 mm.
		% TODO: 被分解的人类模型（可视化）
		\textbf{(c)} An exploded low-polygon human model (around 20,000 faces) showing all body segments. 
		Scale bar, 1 mm.
		% TODO: Blender 中的站立姿势
		\textbf{(d)} The geometric human model assembled in Blender.
		% TODO: 虚幻中的站立姿势
		\textbf{(e)} The complete physics human model in Hutb simulator in the default stand pose.
		% TODO: 虚幻中的跑步姿势
		\textbf{(f)} Human model in a running pose with retracted legs.
		% 透明视图
		% DoFs: 自由度
		\textbf{(g)} DoFs. Translucent bottom view with light-blue arrows indicating hinge joint axes pointing in the direction of positive rotation. 
		% 三个铰合形成 球形关节
		Groups of three hinge joints effectively form ball joints. 
		Cube: 6-DoF free joint required for free CoM motion in the simulator and is not a part of human's internal DoFs.
		\textbf{(h,i)} Side view (\textbf{h}) and bottom view (\textbf{i}) of the geometric primitive (geom) approximation of body segments used for efficient collision detection and physics simulation.
		Blue, collision detection geoms; 
		purple, geoms that have associated adhesion actuators; 
		orange, wing ellipsoid geoms for simulating flight with the advanced fluid force model.
		% contact force: 接触力
		% joint actoators: 关节执行机构
		\textbf{(j)}, Visualization of actuator forces generated when the model fly hangs upside down. 
		The adhesion actuators of the front-right, middle-left and hind-right legs are actively gripping the ceiling (orange); 
		the labrum (mouth) adhesors are also active; 
		other actuators are inactive (white). 
		The arrows visualize net contact forces proportional and opposite to the applied adhesion forces.
		% abdominal abduction: 腹部外展
		\textbf{(k)}, Exaggerated posture showing the coordinated activation of the abdominal abduction and tarsal flexion actuators. 
		Abdominal joints and tarsal joints (yellow) are each coupled with a single tendon actuator that simultaneously actuates multiple DoFs.
	} \label{fig:fig_1}
\end{figure}

% confocal fluorescence microscopy: 共焦 荧光 显微镜检查
% TODO: 用什么设备来捕获人体的高精度图像
We used confocal fluorescence microscopy to capture high-resolution images of the entire adult male human body (Fig.~\ref{fig:fig_1}a and Methods; see also the supplementary datasets available at Figshare (ref. 20)). 
% 识别关节支点
Chitin staining facilitated segmentation of body structures and identification of joint pivot points (Fig.~\ref{fig:fig_1}b). 
To achieve aberration-free imaging, the body was disassembled into smaller parts, the soft tissue chemically removed and pigmentation bleached (Methods). 
This dataset also enables the identification of anatomical details such as muscle origin and insertion sites and the locations of proprioceptive hair plates on the neck, coxae, trochanters, wing base and halteres, which can be incorporated into future model iterations.


% Fiji(分割) -> Blender (减少网格数：文献中有102个自由度)
We manually segmented 67 body components using Fiji\cite{schindelin2012fiji}, then simplified their meshes in Blender22 by reducing the vertex count to enable efficient computational modelling while preserving key morphological features (Fig.~\ref{fig:fig_1}b,c). 
In Blender, we assembled the components into a full-body model and defined the kinematic tree by linking them at 66 identified joint locations (Fig.~\ref{fig:fig_1}b,d and Extended Data Fig.~\ref{fig:extended_fig_1}), yielding 102 degrees of freedom (DoFs) in accordance with the literature (Fig. 1g). 
Biological joints were modelled as single hinge joints (1 DoF) or as combinations of two or three hinge joints (2 and 3 DoFs, respectively). 
These joint models are simplified approximations, particularly for complex articulations such as the neck joint, wing hinge and thorax–coxa articulation\cite{melis2024machine,strausfeld1987neck,gorko2024motor}. 
Joint angles corresponding to the resting pose (Fig.~\ref{fig:fig_1}d,e) and the running pose (Fig.~\ref{fig:fig_1}f) were estimated through visual inspection of videography.


% 激活
% 在未训练的网络中有 类别 选择性偏好特征
\subsection{Modelling body physics} \label{sec:preferred}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{fig/fig_2.pdf}
	\caption{
		\textbf{Preferred feature images of face-selective units in untrained networks.
		}
		\textbf{(a)} Measurements of preferred feature images (PFI) of target units in Conv5 from the reverse-correlation analysis~\cite{bonin2011local}.
		Bright and dark 2D Gaussian filters were generated at a random position as an input stimulus set.
		The PFI was obtained as the summation of stimuli weighted by the corresponding response.
		The initial preferred feature image was calculated from the local Gaussian stimulus set by the classical reverse-correlation method~\cite{bonin2011local}.
		% RNN?
		Then, a new stimulus set was generated as the summation of the obtained PFI and local Gaussian stimuli, with the second preferred feature image then obtained from a new stimulus set.
		This procedure was repeated to obtain the preferred feature image.
		\textbf{(b)} Schematics of the process used to achieve a preferred feature image (PFI) using a generative neural network (GAN) and a genetic algorithm (X-Dream)~\cite{ponce2019evolving}.
		Synthesized images are generated by the GAN with image codes and are fed into an untrained network as input.
		The genetic algorithm finds a new image code that maximizes the response of the target unit.
		The PFI of a target unit is achieved after 100 iterations of this procedure.
		\textbf{(c)} The obtained preferred feature images, using the reverse-correlation method and X-Dream, of the face-selective unit, selective units to non-face class (flower), and units selective to none of the class.
		\textbf{(d)} Illustration of the face-configuration index (FCI) of a face unit's PFI.
		The FCI was defined as pixel-wise correlation between the original face stimuli and the generated PFIs.
		\textbf{(e)} FCI of PFI, using the reverse correlation method, of units selective to each class ($ n_\textrm{Face} = 465 $, $ n_\textrm{Hand} = 7 $, $ n_\textrm{Horn} = 772 $, $ n_\textrm{Flower} = 107 $, $ n_\textrm{Chair} = 63 $).
		\textbf{(f)} FCI of PFI, using X-Dream, of the same units as the units used in (\textbf{e}).
		All box plots indicate the inter-quartile range (IQR between Q1 and Q3) of the dataset,
		the horizontal line depicts the median and the whiskers correspond to the rest of the distribution (Q1-1.5*IQR, Q3+1.5*IQR).
		The face images shown in panels (\textbf{d})-(\textbf{f}) are selected examples from the publicly available dataset~\cite{stigliani2015temporal}.
		The original images are available at [\url{http://vpnl.stanford.edu/fLoc}].
	} \label{fig:fig_2}
\end{figure}


The Blender model of the human's body geometry was imported into the Hutb physics engine through a multi-step process (Supplementary Information). 
First, we generated primitive 'geom' representations of each body part (Fig.~\ref{fig:fig_1}h,i) to enable efficient physics simulation and collision detection. 
Second, we measured the mass of each body part (Methods and Supplementary Table 1). 
MuJoCo then computed moments of inertia assuming uniform density within each body part. 
Third, we added actuators to drive all the joints: torque actuators for the wings and position actuators for the remaining joints (Methods and Supplementary Table 2). 
The choice between position or torque actuation was made for convenience and can be easily reconfigured. 
Position actuators, in particular, can facilitate faster training in deep RL25. 
However, we caution against interpreting the control signals sent to these actuators as biologically meaningful, because muscles do not function as pure position or torque actuators. 
Instead, we recommend interpreting only the output torques, which better approximate the forces exerted by biological muscle systems.


% 几何模式限制神经网络激活
\subsection{Modelling body–environment interactions}\label{subsec2}

% 全局的波传到人脸识别区出现的模式响应 vs 人脸识别模式
% 人脸识别区域几何模式（外形）来重建 人脸识别区域 的激活
% 使用人脑的几何特征模式预测人工神经网络的激活
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{fig/fig_3.pdf}
	\caption{\textbf{Reconstruction of artificial neural network activity with geometric eigenmodes.}
	\textbf{a}, Geometric eigenmodes are derived from the cortical surface mesh by solving the eigenvalue problem,$ \Delta \psi = -\lambda \psi $ (equation (\ref{eq:1})). 
	The modes $ \psi_1, \psi_2, \psi_3, ... \psi_N $ are ordered from low to high spatial frequency (long to short spatial wavelengths). 
	Negative, zero and positive values are coloured blue, white and red, respectively.
	\textbf{b}, Modal decomposition of brain activity data. 
	The example shows how a spatial map, $ y(r,t) $, at a given time, $ t $, can be decomposed as a sum of modes, $ \psi_j $, weighted by $a_j$.
	\textbf{c}, Left, we reconstruct task-evoked data using spatial maps of activation for a diverse range of stimulus contrasts. 
	Right, we reconstruct spontaneous activity by decomposing the spatial map at each time frame and generating a region-to-region FC matrix.
	\textbf{d}, Reconstruction accuracy of seven key HCP task-contrast maps (Supplementary Information~\ref{sec:sup_2_1}) and restingstate FC as a function of the number of modes. 
	Insets show cortical surface reconstructions, demonstrating the spatial scales relevant to the first 10, 100 and 200 modes corresponding to spatial wavelengths of approximately 120, 40 and 30 mm, respectively.
	\textbf{e}, Group-averaged empirical task-activation maps and reconstructions (recon.) obtained using 10, 100 and 200 modes of the seven key HCP task contrasts. 
	Black arrowheads indicate localized activation patterns that are more accurately reconstructed when using short-wavelength modes. 
	\textbf{f}, Group-averaged empirical resting-state FC matrices and reconstructions using 10, 100 and 200 modes.
	} \label{fig:fig_3}
\end{figure}

We first examine the degree to which geometric eigenmodes can explain diverse aspects of human neocortical activity. 
To derive the eigenmodes, we use a mesh representation of a population-averaged template of the neocortical surface (Fig.~\ref{fig:1}a and Derivation of cortical geometric eigenmodes in Methods). 
We then construct the Laplace– Beltrami operator (LBO) from this surface mesh, which captures local vertex-to-vertex spatial relations and curvature, and solve the eigenvalue problem,
\begin{equation} \label{eq:1}
	\nabla^2 \psi = \Delta\psi = -\lambda \psi,
\end{equation}
where $ \nabla $ is the gradient operator, $ \Delta $ is the LBO and $ \psi = \{\psi_1(r), \psi_2(r),...\} $ is the family of geometric eigenmodes with the corresponding family of eigenvalues $ \lambda = \{ \lambda_1, \lambda_2, ... \} $. 
The eigenvalues are ordered sequentially according to the spatial frequency or wavelength of the spatial patterns of each mode (Fig.~\ref{fig:1}a~and Extended Data Fig.~\ref{fig:extended_fig_1}), such that $ \psi_1 $ is the mode with the longest wavelength. 
The resulting eigenmodes are orthogonal, forming a complete basis set to decompose spatiotemporal dynamics unfolding on the cortex as a weighted sum of modes with varying wavelengths (Fig.~\ref{fig:1}b~and Modal decomposition of brain activity in Methods).
Unless otherwise specified, we use $ N=200 $ modes throughtout this study.


Using this decomposition we evaluate the accuracy of geometric eigenmodes in capturing both task-evoked and spontaneous brain activity (Fig.~\ref{fig:1}c) measured in 255 healthy individuals from the Human Connectome Project27 (HCP; HCP data in Methods and Supplementary Information 2). 
For task-evoked activity, we map 47 task-based contrasts drawn from seven different tasks representing distinct evoked activation patterns. 
We then reconstruct each individual’s activation map using an increasing number of modes up to a maximum of 200 (Fig.~\ref{fig:1}d). 
For spontaneous, task-free (so-called resting-state) activity, we reconstruct the spatial map of activity at each time frame and then generate a region-to-region functional coupling (FC) matrix, describing correlations of activity among 180 discrete brain regions per hemisphere28. 
To allow direct comparison between task-evoked and spontaneous recordings, we apply the same regional parcellation to the task-evoked data (Cortical parcellations in Methods). 
Finally, we quantify reconstruction accuracy by calculating the correlation between empirical and reconstructed task-evoked activation maps and spontaneous FC matrices (Fig.~\ref{fig:1}d-f).


We observe that reconstruction accuracy increases with an increasing number of modes across all task contrasts and in the resting state, with $ r \ge 0.38 $ already achieved using just $ N=10 $ modes (Fig.~\ref{fig:1}d). 
Large-scale modes are also differentially recruited across different tasks, suggesting that particular stimuli excite specific modes (Fig.~\ref{fig:1}e). 
Improvements in reconstruction accuracy become slow after ten modes, reaching $ r \geq 0.80 $ at approximately $ N=100 $ modes, with only incremental increases in reconstruction accuracy beyond this point. 
Beause the first 100 modes have wavelengths above around 40 mm (Supplementary Table~\ref{tab:spatial_wavelength}), 
and the inclusion of shorter-wavelength modes only refines reconstruction of localized patterns (arrowheads in Fig.~\ref{fig:1}e), our findings suggest that the data are predominantly comprised of spatial patterns with long spatial wavelengths (see next section for a more detailed analysis).


These results are consistent across all 47 HCP task contrasts (Supplementary Fig.~\ref{fig:supp_1}) and parcellations of varying resolutions (Supplementary Fig.~\ref{fig:supp_2}), but data parcellated at higher resolution require more modes to achieve high reconstruction accuracy due to the low-pass spatial filtering effect of coarser parcellations. 
Our results are also not affected by the use of a population-averaged cortical surface template (rather than individual-specific surfaces) to derive the geometric eigenmodes (Supplementary Figs.~\ref{fig:supp_3}-\ref{fig:supp_5}~and Supplementary Information~\ref{sec:individual_specific}). 
Together these findings indicate that cortical geometric eigenmodes form a compact representation that captures diverse aspects of task-evoked and spontaneous cortical activity. 
Moreover, they show that such activity is dominated by long-wavelength, large-scale eigenmodes.


We next test the hypothesis that geometric eigenmodes provide a more parsimonious and fundamental description of dynamics than eigenmodes derived from a graph-based connectome approximation. 
To this end we compare the reconstruction accuracy of geometric eigenmodes against three alternative connectome-derived eigenmode basis sets (see Fig.~\ref{fig:2}a~for a schematic). 
The first basis set is derived empirically from a connectome mapped with dMRI tractography at vertex resolution and thresholded to obtain a connection density of  0.10\%, as done previously29 (Derivation of connectome eigenmodes in Methods). 
The second basis set is derived from a connectome constructed synthetically according to a homogeneous stochastic wiring process governed by an exponential distance-dependent connection probability to mimic simple, EDR-like connectivity (Derivation of EDR eigenmodes in Methods). 
Because the connection densities of empirical and EDR connectomes differed, we evaluated a third basis set derived from the empirical connectome thresholded at 1.55\% to match the density of the EDR connectome. 
The connectome, EDR and density-matched connectome eigenmodes described above are derived from the graph Laplacian (a discrete counterpart of the LBO) of their respective connectivity matrices (Fig.~\ref{fig:2}b~and Extended Data Fig.~\ref{fig:extended_fig_1}).


To summarize, geometric eigenmodes account for the intrinsic curvature of the cortical surface and local vertex-to-vertex relations in the surface mesh; 
connectome eigenmodes do not consider curvature but capture local spatial relations between mesh vertices, along with short- and long-range connections measured with dMRI; 
and EDR eigenmodes account for the effect of a homogeneous, stochastic, distance-dependent connection rule without fully capturing the cortical geometry (Fig.~\ref{fig:2}a). 
Contrasting these different basis sets thus allows us to disentangle the contributions to brain dynamics of cortical geometry from structural connectivity.


Direct comparison of the reconstruction accuracy of these different basis sets shows that geometric eigenmodes consistently show the highest reconstruction accuracy across both spontaneous (Fig.~\ref{fig:2}c) and task-evoked (Fig.~\ref{fig:2}d) data. 
EDR eigenmodes perform nearly as well as geometric eigenmodes whereas connectome eigenmodes are the least accurate. 
This finding holds true regardless of the parcellation used (Extended Data Figs.~\ref{fig:extended_fig_2}~and~\ref{fig:extended_fig_3}), the specific connection density used to generate the connectome eigenmodes (Supplementary Figs.~\ref{fig:extended_fig_6}~and~\ref{fig:extended_fig_7}~and Supplementary Information~\ref{sec:thresholding_effect}) and whether we generate the connectome using a discrete regional parcellation rather than at vertex resolution (Supplementary Fig.\ref{fig:extended_fig_8} and Supplementary Information~\ref{sec:thresholding_effect}). 
We additionally find that geometric eigenmodes show stronger out-of-sample generalization than principal components of the functional data themselves (calculated via principal component analysis (PCA); Supplementary Fig.\ref{fig:supp_9}, Extended Data Fig.~\ref{fig:extended_fig_4} and Supplementary Information~\ref{sec:comparison_eigenmodes_derived}) and better performance than Fourier spatial basis sets (Extended Data Fig.\ref{fig:extended_fig_5}, Supplementary Information~\ref{sec:comparison_fourier}~and Comparisons with statistical basis sets in Methods~\ref{sec:sets_comparisons}).

% 长波主导神经网络激活
\subsection{Imitation learning of locomotion}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{fig/fig_4.pdf}
	\caption{\textbf{Geometric eigenmodes benchmarked against connectome-based eigenmodes.}
	\textbf{a}, Schematic of the anatomical properties used to derive eigenmodes for cortical geometry, the connectome and the EDR connectome. 
	Geometric eigenmodes rely on local surface mesh information such as links (blue) between neighbouring surface mesh vertices (dots) and curvature. 
	Connectome eigenmodes rely on local links between mesh vertices (blue) and short- and long-range connections (magenta) reconstructed empirically from dMRI. 
	EDR eigenmodes rely on connections (red) generated from a stochastic wiring process in which the probability of connection between vertices exponentially decays as a function of their distance.
	\textbf{b}, Example connectome and EDR eigenmodes. 
	Negative, zero and positive values are coloured blue, white and red, respectively. 
	Despite some similarities, the spatial patterns of the modes are distinct from those derived using cortical geometry (compare with Fig.~\ref{fig:1}a).
	\textbf{c}, Reconstruction accuracy of resting-state FC matrices achieved by geometric, EDR and two variants of connectome eigenmodes: 
	one using a connectome as defined using previous methods\cite{naze2021robustness} and the other with the same connection density as the EDR connectome to allow fair comparison (for other densities see Supplementary Figs.~\ref{fig:supp_6}~and~\ref{fig:supp_7}).
	} \label{fig:fig_4}
\end{figure}

\subsubsection{Walking}


\subsubsection{Running}
% 肌肉驱动的人类跑步模拟：https://simtk.org/projects/runningsim/

Reconstructions of both spontaneous and task-evoked data with geometric eigenmodes show that the spatial organization of brain activity is dominated by patterns with spatial wavelengths of about 40 mm or longer (Fig.~\ref{fig:1}d–f). 
This result counters classical approaches to analysis of neuroimaging data, in which stimulus-evoked activations are mapped by thresholding statistical maps to identify focal, isolated areas of heightened activity. 
This classical approach rests on the assumption that focal loci represent discrete brain regions putatively engaged by the stimulus and that subthreshold activity in other regions is of negligible interest. 
The surprisingly long-wavelength content of task-activation data (Fig.~\ref{fig:1}d-e) suggests that classical procedures focus only on the tips of the iceberg and obscure the underlying spatially extended and structured patterns of activity evoked by the task (see Extended Data Fig.~\ref{fig:extended_fig_6}~for an explanation of the reasons involved). 
These observations accord with the theoretical predictions of NFT and previous analyses of task-evoked electroencephalography (EEG) signals\cite{robinson2001modal,wingeier2001spherical}.


Here we leverage the modal decomposition described in Fig.~\ref{fig:1}b to characterize the complete spatial pattern—the entire iceberg— of task-evoked activation. 
To this end we analyse the spatial power spectrum obtained using a geometric mode decomposition of group-averaged unthresholded activation maps from the 47 task contrasts in HCP\cite{van2013wu,gorgolewski2015neurovault} (Modal power spectra of task-evoked activation maps in Methods). 
As an independent replication, we also analyse 10,000 unthresholded activation maps from 1,178 independent experiments available in the NeuroVault repository\cite{van2013wu,gorgolewski2015neurovault}, thus providing a comprehensive picture of the diversity of stimulus-evoked activation patterns mapped in the human brain.


Despite the wide range of stimuli, paradigms and data-processing approaches used to acquire these activation maps, we observe that a large fraction of power in the maps is concentrated in the first 50 modes, corresponding to spatial wavelengths greater than around 60 mm (Fig.~\ref{fig:3}a; similar results are found separately for each of the key HCP task-contrast maps; Extended Data Fig.~\ref{fig:extended_fig_7}). 
Using surrogate data, we confirm that these findings cannot be explained by the spatial smoothing  induced by typical fMRI processing pipelines, which can filter out short-wavelength spatial patterns of activity (Extended Data Fig.~\ref{fig:extended_fig_8}~and Supplementary Information~\ref{sec:modal_power_spectra}). 
We further observe that incremental, sequential removal of long-wavelength modes has a much greater impact on reconstruction accuracy than removal of short-wavelength modes (Fig.~\ref{fig:3}b~and Contributions of long- and short-wavelength modes in Methods~\ref{sec:wavelength_contributions}). 
For instance, across the seven key HCP task contrasts, removal of the top 25\% long-wavelength modes (modes 1–50) yields a drop in reconstruction accuracy of around 40–60\% whereas removal of the top 25\% short-wavelength modes (modes 151–200) yields a drop of only around 2–4\% (Fig.~\ref{fig:3}b, insets). 
These results indicate that, on temporal and spatial scales accessible with fMRI, evoked cortical activity comprises large-scale, nearly brain-wide spatial patterns, challenging classical views that such activity should be described in terms of discrete, isolated and anatomically localized activation clusters.


% 波动力学连接和几何和功能
\subsection{Hierarchical vision-guided walking}


%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width=0.9\textwidth]{fig/fig_5.pdf}
%	\caption{
%	} \label{fig:fig_5}
%\end{figure}


Geometric eigenmodes of the cortex are obtained by solving the eigenvalue problem of the LBO, which is also known as the Helmholtz equation (equation (\ref{eq:1})). 
In physically continuous systems, the solutions of the Helmholtz equation correspond to the spatial projections of the solutions of a more general wave equation, such that the resulting eigenmodes inherently represent the vibrational patterns, or standing waves, of the system’s dynamics\cite{levy2006laplace}. 
This equivalence implies that the superior efficacy of geometric eigenmodes in the reconstruction of diverse patterns of brain activity results from a fundamental role of wave dynamics in shaping these patterns, as predicted by NFT. 
This prediction has been confirmed through models of EEG recordings21,35, but waves across the whole brain have only recently been observed in fMRI signals\cite{robinson2005multiscale,bolt2022parsimonious} and thus far lack a theoretical explanation. 
Here we use NFT and geometric eigenmodes to show that wave dynamics can provide a unifying account of diverse empirical and physiological phenomena observed at scales accessible with fMRI.


We model neural activity using an isotropic damped NFT wave equation without regeneration\cite{robinson1997propagation} (Fig.~\ref{fig:4}a~and NFT wave model in Methods~\ref{sec:NFT_model}). 
Under this model, activity propagates between points on the neocortex through their white-matter connectivity with a strength that decays approximately exponentially with distance (Supplementary Fig.~\ref{fig:extended_fig_10}~and Supplementary Information~\ref{sec:NFT}~and~\ref{sec:NFT_wave}). 
To simulate resting-state neural activity we use a white noise input to mimic unstructured stochastic fluctuations\cite{robinson2005multiscale} (Modelling resting-state dynamics in Methods~\ref{sec:modelling_resting}). 
We compare the performance of this simple wave model with a biophysically based neural mass model (balanced excitation–inhibition (BEI) model) that has been used extensively to understand resting-state fMRI signals\cite{deco2014local} (Fig.~\ref{fig:4}a~and Neural mass model in Methods~\ref{sec:neural_mass}). 
The neural mass model is closely aligned with the classical, connectome-centric view of brain function, representing dynamics as the result of interactions between neuronal populations in discrete anatomical regions, coupled according to an empirically measured connectome.


We first compare the efficacy of the two models in capturing distinct and commonly studied properties of spontaneous, task-free FC: namely, static pairwise FC (edge FC), static node-level average FC (node FC) and time-resolved dynamic properties of FC (FCD) (Modelling resting-state dynamics in Methods~\ref{sec:modelling_resting}). 
Across all FC-based benchmark measures, the wave model shows comparable or superior performance in reconstruction of empirical data relative to the neural mass model (Fig.~\ref{fig:4}b). 
The wave model also captures time-lagged properties\cite{raut2021global,bolt2022parsimonious,mitra2015lag} of empirical resting-state activity more accurately than the mass model (Extended Data Fig.~\ref{fig:extended_fig_9}~and Measuring time-lagged properties of resting-state dynamics in Methods~\ref{sec:dynamics_measurement}). 
This strong performance of the wave model is remarkable given its relative simplicity: the wave model only requires the geometry of the cortex (that is, the surface mesh) as input and includes one fixed parameter and one free parameter ($ r_s $) for fitting to data (Extended Data Fig.~\ref{fig:extended_fig_10}) whereas the neural mass model requires a dMRI-derived interregional anatomical connectivity matrix and comprises 15 fixed parameters and four free parameters (Supplementary Information~\ref{sec:mass_optimization}). 
These considerations indicate that wave dynamics offer a more accurate and parsimonious mechanistic account of macroscale, spontaneous cortical dynamics captured by fMRI.


We next consider stimulus-evoked cortical activity in the wave model. 
We analyse cortical responses to sensory stimulation of primary visual cortex (V1), because it elicits a well-defined hierarchy of regional cortical responses\cite{felleman1991distributed,chaudhuri2015large} (Modelling stimulus-evoked dynamics in Methods). 
A 1 ms pulse input to V1 yields a propagating wave of activity that rapidly splits along the dorsal and ventral visual processing streams (Fig.~\ref{fig:4}c (arrows) and Supplementary Video 1), consistent with the mainstream understanding of hierarchical visual processing\cite{goodale1992separate}. 
Remarkably, this result indicates that geometric constraints on travelling waves of evoked activity are sufficient for the segregation of the dorsal and ventral processing streams, which have traditionally been thought to be driven primarily by complex patterns of layer-specific connectivity\cite{felleman1991distributed,goodale1992separate,markov2014anatomy}. 
Furthermore, the temporal profile of evoked responses across the visual system follows a well-defined timescale hierarchy, with higher-order association areas showing peak responses that are delayed and prolonged compared with lower-order visual areas (Fig.~\ref{fig:4}d). 
These findings thus indicate that this hierarchical ordering, previously identified in experimental and modelling studies\cite{chaudhuri2015large,hasson2008hierarchy,murray2014hierarchy}, emerges naturally from waves of excitation propagating through the cortical medium. Critically, this hierarchical temporal ordering of areal responses strongly correlates with an independent anatomical measure of the cortical processing hierarchy based on non-invasive estimates of myeloarchitecture (T1-weighted (T1w) and T2-weighted (T2w) ratio)\cite{glasser2011mapping,gao2020neuronal}. 
This correlation is particularly strong within the visual processing hierarchy ($ r = -0.72 $, one-sided spin-test $ P $ value ($P_{spin}$) = 0.003; Fig.~\ref{fig:4}e) but is also present when considering all cortical areas ($ r = -0.44 $, $ P_{spin} = 0.037 $; Supplementary Fig.~\ref{fig:supp_11}). 
Together, our modelling results show how simple wave dynamics unfolding on the geometry of the cortex provide a unifying generative mechanism for capturing complex properties of spatiotemporal brain activity.


\subsubsection{Geometry constrains subcortical activity}
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{fig/fig_4.pdf}
	\caption{
	} \label{fig:4}
\end{figure}


Our analyses thus far have focused on the strong coupling of geometry and dynamics in the neocortex. 
We next investigate this coupling in non-neocortical areas, focusing on the thalamus, striatum and hippocampus, because these structures have geometries easily captured using MRI data and their functional organization has been extensively studied\cite{tian2020topographic}.


We first generalize our eigenmode analysis to three-dimensional (3D) volumes (Estimating the geometric eigenmodes of non-neocortical structures in Methods), yielding geometric eigenmodes that extend spatially through the three spatial dimensions of each structure. 
Next, to fully capture the macroscale functional organization of these non-neocortical regions, we apply a widely used manifold learning procedure to voxel-wise FC data to obtain the key functional gradients in each structure\cite{haak2018connectopic} (Mapping the functional organization of non-neocortical structures in Methods). 
These functional gradients describe the principal axes of spatial organization dictated by similarities in FC, thus representing the dominant modes of variation in functional organization, ordered according to the percentage of variance in FC similarity that they explain.


The spatial profiles of the first three functional gradients of the thalamus, striatum and hippocampus (accounting for 24, 50 and 47\% of the variance in FC similarity, respectively) show a near-perfect match to the first three geometric eigenmodes (Fig.~\ref{fig:5}a–c; spatial correlations $ r\geq0.93 $). 
This tight correspondence generalizes out to the first 20 modes and first 20 gradients of each structure (with the first 20 gradients respectively accounting for 49, 70 and 68\% of total variance in FC similarity), with all absolute spatial correlations $ |r| > 0.5 $, except for the 20th gradient and 20th mode in the striatum and hippocampus (Fig.~\ref{fig:5}d–f). 
This strong relationship is striking given that the functional gradients are generated via a complex processing pipeline applied to fMRI-derived FC measures whereas the eigenmodes are derived simply from each structure’s geometry, independent of the functional data. These findings suggest that the functional organization of non-neocortical structures derives directly from their geometric eigenmodes.


%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width=0.9\textwidth]{fig/fig_5.pdf}
%	\caption{
%	} \label{fig:5}
%\end{figure}



%\subsection{Detection of face images using the responses of face-selective units}
%
%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width=0.9\textwidth]{fig/face_3.pdf}
%	\caption{
%		\textbf{Detection of face images using the response of face units in untrained networks.
%		}
%		(\textbf{a}) Design of the face detection task and SVM classifier using the responses of the untrained AlexNet.
%		During this task, face or non-face images were randomly presented to the networks and the observed response of the final layer was use d to train a support vector machine (SVM) to classify whether the given image was a face or not.
%		Among 60 images from each class (face, hand, horn, flower, chair, and scrambled face) that were not used for face unit selection, 40 images were randomly sampled for the training of the SVM, and the other 20 images were used for testing.
%		The images shown are selected examples from the publicly available dataset~\cite{stigliani2015temporal}.
%		The original images are available at [\url{http://vpnl.standford.edu/fLoc}].
%		(\textbf{b}) Performance on the face detection task using a single unit randomly sampled from face-selective units ($ n = 465 $) and units without selective responses to any image classes ($ n = 7776 $).
%		The channel level was measured by the shuffled responses of face-selective units in the untrained network.
%		The error bar indicates the standard deviation of each unit.
%		Each bar indicates the mean and the error bar indicates the standard deviation of performance of each unit.
%		(\textbf{c}) Performance of the face detection task using face-selective units and non-selective units when varying the number of units from 1 to 456.
%		The dashed line indicates the detection performance using all units in Conv5 ($ n=43,264 $).
%		Each line indicates the mean and the shaded area indicates the standard deviation for 100 repeated trials of the random sampling of units.
%		(\textbf{d}) Performance on the face detection task using face-selective units ($ n=465 $) and then using all units in Conv5 ($ n=43,264 $).
%		Each bar indicates the mean and the error bar indicates the standard deviation for 100 repeated trials of the random sampling of units.
%	} \label{fig:detection}
%\end{figure}
%
%
%We tested whether the selective responses of these face units could provide reliable information with which to detect between faces and non-face objects.
%During this task, face ($ n=40 $) or non-face ($ n=40 $) images were randomly presented to the networks, and the observed response of the final layer was used to train a support vector machine (SVM) to classify whether the given image was a face or not (\ref{fig:detection}a).
%First, we compared the detection performance of the SVM using a single unit randomly sampled from face-selective units and using units without selective responses to any image classes.
%We confirmed that the SVM trained with a single face-selective unit shows noticeably higher performance that those measured from shuffled responses, whereas the SVM trained with units without selectivity does not 
%(\ref{fig:detection}b,
%Face unit vs. Response shuffled, 
%$ n_\textrm{face} = 465 $,
%two-sided rank-sum test,
%$ P = 2.97 \times 10 ^{-121} $,
%$ r_{rbc} = 7.68 \times 10^{-1} $;
%Response shuffled vs. Non-selective unit, 
%$ n_\textrm{non-selective} = 7,776 $,
%two-sided rank-sum test, NS, 
%$ P = 1.10 \times 10^{-1} $,
%$ r_{rbc} = 4.52 \times 10^{-2} $,
%two-sided Kolmogorov-Smirnov test,
%$ P = 1.93 \times 10^{-1} $,
%$ d = 2.12 \times 10^{-2} $
%).
%Then, extending the test to various numbers of units, we compared the detection performance of this SVM using face-selective units with the performance when using the same number of randomly sampled non-selective units.
%We confirmed that the SVM trained with multiple face-selective units shows noticeably better performance that that trained with the same number of non-selective units, 
%as the number of units used in each condition was varied from $ n=1 $ to 465 (total number of face units in untrained networks)
%(\ref{fig:detection}c,
%Face vs. Non-selective units, 
%$ n_\textrm{trial} = 100 $,
%two-sided rank-sum test, 
%$ P \leq 1.45 \times 10^{-33} $,
%$ r_{rbc} \geq 8.74 \times 10^{-1} $
%).
%We also found that the SVM using face units ($ n=465 $) nearly matches the performance of the SVM using all units in the final layer ($ n=43,264 $)
%(\ref{fig:detection}d, 
%Face vs. All units, 
%$ n_\textrm{trial} = 100 $,
%two-sided rank-sum test, NS, 
%$ P = 1.90 \times 10^{-1} $,
%$ r_{rbc} = 9.29 \times 10^{-2} $,
%two-sided Kolmogorov-Smirnov test,
%$ P = 1.90 \times 10^{-1} $,
%$ d = 9.20 \times 10^{-3} $
%).
%Furthermore, we found that face units enable the networks to detect faces with various sizes, position, and rotations even when such image conditions were held constant when training the SVM classifier.
%
%
%Notably, we also found that the SVM can successfully detect faces when it is trained with the responses of units selective to non-face classes, 
%similar to the results in a previous experiment in human~\cite{haxby2001distributed},
%whereas it failed to detect with units not selective to any of the classes.
%To compare our results with the experiment condition of the previous human experiment~\cite{haxby2001distributed},
%we first trained the SVM using the responses of four distinct populations:
%(1) all of the units selective to each class (All-selective),
%(2) units selective to non-face classes (Non-face-selective),
%(3) face-selective units only (Face-selective),
%and (4) units not selective to any of the classes (Non-selective).
%As a result, we found that the SVM trained with non-face-selective units showed a performance comparable with the results of Haxby et al.~\cite{haxby2001distributed}.
%Interestingly, the performance was also comparable with those with all-selective units and those with face-selective units only,
%similar to the results in a previous experiment in human~\cite{haxby2001distributed}.
%This result is understandable considering that there are only five image classes;
%thus, even non-face-selective units can provide information for discriminating face and non-face images by generating different levels of activities for each class.
%Taken together, these results imply that the information provided by selective units that emerge in the untrained networks is sufficient to detect between faces and non-face objects.
%
%
%%\subsection{The emergence of face-selectivity in trained DNNs}
%
%
%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width=1.0\textwidth]{fig/face_4.pdf}
%	\caption{
%		\textbf{Effect of training on face-selectivity in untrained networks.
%		}
%		(\textbf{a}) Three different datasets modified from publicly available ImageNet~\cite{ILSVRC15} were used for the training of the network for image classification: 
%		(1) face-reduced ImageNet, 
%		(2) original Imagenet, 
%		and (3) ImageNet with added face images.
%		For copyright reasons, the face image shown here is not the actual image used in the experiments.
%		The original images are replaced with images with similar contents for display purposes.
%		The original images are available at [\url{https://www.image-net.org/download}].
%		Images shown are available at [\url{https://www.shutterstock.com},\url{http://vpnl.stanford.edu/fLoc/}~\cite{stigliani2015temporal}].
%		(\textbf{b}) Face-selectivity index of face-selective units in untrained network and in networks trained with the three datasets ($ n_\textrm{Untrained} = 4,267 $, $ n_\textrm{Reduced} = 2,452 $, $ n_\textrm{Original} = 3,561 $, $ n_\textrm{Face} = 3,585 $).
%		(\textbf{c}) The number of face-selective units in untrained networks and in networks trained with three datasets ($ n_\text{net} = 10 $).
%		(\textbf{d}) Face detection performance of untrained networks and of networks trained with three different datasets ($ n_\textrm{trial} = 1,000 $).
%		(\textbf{e}) The obtained preferred feature images (PFI), using reverse-correlation method of the face-selective unit on each network.
%		All box plots indicate the inter-quartile range (IQR between Q1 and Q3) of the dataset,
%		the horizontal line depicts the median and the whiskers correspond to the rest of the distribution (Q1-1.5*IQR, Q3+1.5*IQR).
%	} \label{fig:effect}
%\end{figure}
%
%
%We tested a scenario in which our current model can corroborate the conflicting observations regarding the role of visual experience for the development of face-selectivity.
%A previous report suggested that visual experience is necessary for the emergence of face-selectivity by showing that monkeys raised without exposure to faces lack face-selective domains~\cite{arcaro2017seeing}.
%On the other hand, another recent study showed that the face-selective area develops robustly in congenitally blind humans, suggesting that visual experience is not necessary for face-selectivity~\cite{arcaro2017seeing}.
%Regarding these conflicting results, we examined how face-selective units in untrained networks can be affected by training with visual inputs.
%
%
%To investigate the effect of training on a face image set,
%we prepared the following three different stimulus sets:
%(1) face-reduced ImageNet: 500 classes including no recognizable face images were manually curated from the ILSVRC 2010 dataset according to a visual inspection by the authors,
%(2) the original ImageNet, 
%and (3) the original ImageNet with added face images used in the current study~\ref{fig:effect}a.
%Then, the network was trained with each of these image sets.
%First, we found that the FSI of the face-selective units was significantly decreased after being trained to the face-reduced image set 
%(~\ref{fig:effect}b,
%Untrained vs. Face-reduced,
%$ n_\textrm{Untrained} = 4,267 $,
%$ n_\textrm{Reduced} = 2,452 $,
%two-sided rank-sum test,
%$ P = 2.99 \times 10^{-28} $,
%$ r_\textrm{rbc} = 6.76 \times 10^{-1} $
%),
%whereas it was increased after being trained to the face-including image sets 
%(Untrained vs. Face-included,
%$ n_\textrm{Face} =3585 $,
%two-sided rank-sum test,
%$ P = 1.21 \times 10^{-3} $,
%$ r_{rbc} = 2.60 \times 10^{-1} $
%).
%Notable, the FSI was significantly decreased after being trained to the original ImageNet dataset that contains images of faces but has no group labeled as face
%(~\ref{fig:effect}b, Untrained vs. Original, 
%$ n_\textrm{Original} = 3,561 $,
%two-sided rank-sum test,
%$ P = 9.34 \times 10^{-45} $,
%$ r_\textrm{rbc} = 8.15 \times 10^{-1} $
%).
%This suggests that the tuning of face-selective units could either be sharpened or weakened by training with distinct stimulus sets.
%
%% Fig.4 c
%Next, we found that the number of face-selective units observed was greater in the network trained with face-including image set compared to that trained to face-reduced images 
%(\ref{fig:effect}c, Untrained vs. Trained,
%$ n_\textrm{Net} = 10 $,
%two-sided rank-sum test,
%$ P \leq 1.40 \times 10 ^{-3} $,
%$ r_\textrm{rbc} \geq 5.72 \times 10^{-1} $
%).
%Interesting, however, we found that the number of face-selective units, when trained to face-including images, appeared to be smaller than that of untrained networks.
%These results imply that the training process of the network to face-including images selectively sharpens the tuning of face units so that the selectivity of strongly tuned units is sharpened while the weakly tuned units are pruned.
%In this condition, the face detection performance of the networks would improve in face-trained networks even if the number of face units decreased compared to the initial, untrained condition.
%To validate this scenario, we trained the SVM using the response of face-selective units for a face detection task in an untrained network and in the three networks trained to each type of data set.
%As predicted, we found that the face detection performance was significantly increased in the networks trained to the face-including image set compared to that of the untrained network
%(~\ref{fig:effect}d, Untrained vs. Face included, 
%$ n_\textrm{trial} = 1000 $,
%two-sided rank-sum test,
%$ P = 1.04 \times 10^{-3} $,
%$ r_\textrm{rbc} = 2.60 \times 10^{-1} $
%),
%whereas the face detection performance of the network trained to the face-reduced image set was significantly decreased compared to the untrained network
%(~\ref{fig:effect}, Untrained vs. Face-reduced,
%$ n_\textrm{trial} = 1,000 $,
%two-sided rank-sum test,
%$ P = 1.06 \times 10^{-22} $,
%$ r_\textrm{rbc} = 6.42 \times 10^{-1} $
%).
%Furthermore, we found that the PFI of the face-selective unit shows a clear face configuration in the network trained to face-including natural images,
%whereas the face configuration is disrupted in network trained to face-reduced dataset (\ref{fig:effect}e).
%This result is consistent with previous observation of decreased face-selectivity in face-deprived monkeys~\cite{arcaro2017seeing}.





\section{Discussion}

\section{Method} \label{sec:method}

% TODO 人体没有解剖样本
% OpenSim -> https://github.com/MyoHub/myoconverter -> MuJoCo
% Z-anatomy：人体解剖学的开放三维图谱：https://simtk.org/projects/z-anatomy
% https://www.z-anatomy.com/
% 人体的 Blender 解剖模型 https://www.blenderkit.com/?query=category_subtree:anatomy
% 3D人体解剖图谱: https://sketchfab.com/Z-Anatomy
% 人体解剖三维模型：https://www.cgtrader.com/3d-models/human-anatomy
\subsection{Preparation of anatomical samples}

% 使用酒精洗，并解剖
The five-to-six-day-old flies (w1118;+;+, backcrossed to M. Heisenberg's CantonS for ten generations) were anaesthetized on ice, briefly washed with ethanol and dissected under PBS-T (PBS+ 0.1\% Triton X-100).
% 识别之间的距离
Disassembling the fly into manageable elements allowed us to use high-magnification, high-numerical aperture (NA) objectives that have—in relation to the size of a fly’s body—short working distances, but have the benefit of higher axial resolution than the lower-magnification and lower-NA objectives. 
Heads, wings, thoraces with abdomens, fore legs, midlegs and hind legs were transferred to individual tubes.
All body parts except the wings 
were incubated with 0.25 mg ml$ ^-1 $ trypsin in PBS-T for 48 h at 37 C to remove the soft tissues.
The cuticle was then bleached in 20\% H$ _2 $O$ _2 $ for 24h, and the exoskeleton and tendons were stained overnight with Congo Red (0.5 mg ml$ _1 $), Sigma-Aldrich, C676-25G), a bright and comparatively photostable chitin-binding dye that stains both soft, membranous and hard, sclerotized cuticle.
It also shows affinity to tendons and fine tendrils, which is very convenient for identifying muscles' origin and insertion sites, even in the absence of soft tissues.
% 识别本体感受的发板
The dataset also enables the identification of locations of the proprioceptive hair plates of the neck, coxae, trochanters, wing base and halteres-information that can be incorporated into future versions of the model. 
The samples were dehydrated in ethanol and mounted in methyl salicylate (Sigma-Aldrich, M6752), which has a refractive index very close to that of glass, facilitating imaging throughout the relatively thick and bulky samples without degradation of the signal. 
Serial optical sections were obtained on a Zeiss 880 confocal microscope at 2 $ \mu $m with a Plan-Apochromat 10×/0.45 NA objective, 1-$ \mu $m intervals with a LD-LCI 25$ \times $ / 0.8 NA objective or 0.3 $ \mu $m with a Plan-Apochromat 40×/1.3 NA objective. The 560-nm laser line was used to excite Congo Red.



\subsection{Blender model of body geometry} \label{sec:derivation}


Three-dimensional meshes were extracted from the confocal stacks using Fiji's 3D viewer plug-in\cite{schindelin2012fiji} and imported into Blender\cite{community2018blender}.
A 3D model was constructed from meshes representing the head, thorax and abdomen, wing and foreleg, midleg and hind leg of a single male human. 
Appendage meshes were mirrored across the body's medial plane (Extended Data Fig. 1a). 
This model was used as the reference for creating a simplified lower-polygon-count model, in which the total number of vertices was reduced from 22.6 million to 20,000 (Extended Data Fig.~\ref{fig:extended_fig_1}b).
This simplified model consisted of 67 articulated body segments (Extended Data Fig.~\ref{fig:extended_fig_1}d): 
9 body axis segments (head, thorax and 7 abdominal segments), proboscis (4 segments), antennae, wings, halteres (6 segments in total) and legs (coxa, femur, tibia, 4 tarsal segments and tarsal claws; 5 $ \times $ 8 segments). 
The exact positions of joints, articulations and axes of joints' rotation were determined with high confidence from confocal microscopy data (Fig.~\ref{fig:extended_fig_1}b and Extended Data Fig.~\ref{fig:extended_fig_1}c). 
The model was posed in the rest position and rigged in Blender by creating constraints defining movement of the body segments with respect to each other. 
Each of the 67 body segments was assigned (parented to) a control element called 'bone', forming a hierarchical kinematic tree system resembling a skeleton called 'armature' (Extended Data Fig.~\ref{fig:extended_fig_1}d).





\subsection{PhysX model of body physics} \label{sec:body_physics}


The Blender model was then exported to Unreal Engine using the Blender-For-UnrealEngine-Addons (https://github.com/xavier150/Blender-For-UnrealEngine-Addons). 
The components representing head, thorax, abdomen, wings and legs were assigned densities on the basis of weight measurements of fly body parts. 
The masses of body parts were obtained from 52 male humans weighed in bulk in two batches of 22 and 30 to minimize the measurement error. 
% 使用什么秤
The human were weighted with the Meter Toledo XS104 analytical balance with a readability of 0.1 mg and a linear deviation of 0.2 mg. 
% 秤没有翅膀的重量
% TODO 怎么秤手的重量：体成分分析仪、人体秤（健身房、分段式测量）
First, the wings were removed from all of the flies in the batch and the wingless flies were weighed, followed by weighing after the sequential removal of legs, heads and thoraxes. 
The values were subtracted from the whole-body weight. 
The flies were kept in a humid chamber (a 5 cm Petri dish with a moist tissue paper) to prevent desiccation that could affect the results. 
The measured masses were: 
head, 0.15 mg;
thorax, 0.34 mg;
abdomen, 0.38 mg; 
legs (each) , 0.0162 mg;
wings (each), 0.008 mg. 
This corresponds to a total fly mass of 0.983 mg (Supplementary Table 1).
The full body length of the model is 0.297 cm, and the wing-span is 0.604 cm. 


% 关节约束在 Blender 中确定
Joint limits were at first determined using Blender's inverse kinematics tool. 
We started with fairly tight joint limits and then used reference images of extreme articulated postures (mostly from grooming behaviours) to increase joint limits as required, until all reference poses could be achieved. 
We then refined the leg joint limits using automated inverse kinematics fitting of the model to 392 frames from manually annotated grooming behaviour videos (more details below). 
The sensory-system details in the model's default configuration are shown in Supplementary Table 3. 
DoFs were actuated using torque or position actuators, with certain DoFs (abdomen and tarsi) coupled by tendons (Supplementary Table 2). 
For position actuators, control ranges were set to be equal to the corresponding joint ranges. 
% 半物理：通过物理交互实现运动三维人体模型(https://arxiv.org/abs/2507.23778)
For more details on building the human PhysX model, see the Supplementary Information.


\subsection{Analysis of leg DoFs} \label{sec:HCP_data}

To verify our approximation of the leg DoFs and leg joint ranges, we applied the following procedure. 
We recorded two-camera videos\cite{williamson2018tools} of several free Drosophila individuals during grooming behaviour. 
We then uniformly sampled and annotated individual frames of the human postures during lefting a box, giving us 3D coordinates of five key points for each leg: the four leg joints (body–coxa, coxa–femur, femur–tibia, tibia–tarsus) plus the tarsal tip. 
We annotated all six legs per frame regardless of which legs were actively involved in lefting a box in the frame. 
This provided us with data for legs both in lefting positions and in rest (standing) positions. 
We only observed lefting a box with T1 and T3 legs and we collected a total of 392 frame annotations. 
Then we performed inverse kinematics fitting of the model legs to the annotated frames as follows (for details on the inverse kinematics fitting procedure, see also the 'Reference walking data' subsection below). 
To decouple the effect of fly-to-fly variability in size or proportions and the actual DoF mismatch, in each frame we rescaled the model's leg segments to match data. 
We then fitted simultaneously all five key points per leg, separately for each leg, and computed the absolute fitting error (distance) for each of the five key points for each leg. 
Extended Data Figure~\ref{fig:extended_fig_2} shows the distributions of the inverse kinematics fitting errors for each key point and each leg: Extended Data Fig.~\ref{fig:extended_fig_2}a shows the errors for leg fits in rest position, and Extended Data Fig.~\ref{fig:extended_fig_2}b shows errors in grooming positions. 
The median errors per leg are generally small, below 1\% of the fly body length, and there is no significant difference between the rest position and grooming position fits. 
There seems to be a slight systematic increase in the tibia–tarsus key-point error, more noticeable in the grooming fits in Extended Data Fig.~\ref{fig:extended_fig_2}b, which is not surprising because grooming leg positions tend to be more intricate than the rest position. 
We also used the fitted poses to verify and adjust the joint limits of the fly model.





\subsection{Data availability} \label{sec:data_availability}


\subsection{Code availability} \label{sec:code_availability}


\section{Extended Figure}

\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_1.pdf}
	\caption{
	} \label{fig:extended_fig_1}
\end{figure}


\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_2.pdf}
	\caption{
	} \label{fig:extended_fig_2}
\end{figure}


\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_3.pdf}
	\caption{}
	\label{fig:extended_fig_3}
\end{figure}


\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_4.pdf}
	\caption{}
	\label{fig:extended_fig_4}
\end{figure}


\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_5.pdf}
	\caption{}
	\label{fig:extended_fig_5}
\end{figure}



\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_6.pdf}
	\caption{}
	\label{fig:extended_fig_6}
\end{figure}


\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_7.pdf}
	\caption{}
	\label{fig:extended_fig_7}
\end{figure}


\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_8.pdf}
	\caption{}
	\label{fig:extended_fig_8}
\end{figure}


\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_9.pdf}
	\caption{}
	\label{fig:extended_fig_9}
\end{figure}


\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.9\textwidth]{fig/extended_fig_10.pdf}
	\caption{}
	\label{fig:extended_fig_10}
\end{figure}



\section{Conclusion}\label{sec13}

Conclusions may be used to restate your hypothesis or research question, restate your major findings, explain the relevance and the added value of your work, highlight any limitations of your study, describe future directions for research and recommendations. 

In some disciplines use of Discussion or 'Conclusion' is interchangeable. It is not mandatory to use both. Please refer to Journal-level guidance for any specific requirements. 

\backmatter

\bmhead{Supplementary information}

If your article has accompanying supplementary file/s please state so here. 

Authors reporting data from electrophoretic gels and blots should supply the full unprocessed scans for key as part of their Supplementary information. This may be requested by the editorial team/s if it is missing.

Please refer to Journal-level guidance for any specific requirements.

\bmhead{Acknowledgements}

Acknowledgements are not compulsory. Where included they should be brief. Grant or contribution numbers may be acknowledged.

Please refer to Journal-level guidance for any specific requirements.

\section*{Declarations}

Some journals require declarations to be submitted in a standardised format. Please check the Instructions for Authors of the journal to which you are submitting to see if you need to complete this section. If yes, your manuscript must contain the following sections under the heading `Declarations':

\begin{itemize}
\item Funding
\item Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)
\item Ethics approval and consent to participate
\item Consent for publication
\item Data availability 
\item Materials availability
\item Code availability 
\item Author contribution
\end{itemize}

\noindent
If any of the sections are not relevant to your manuscript, please include the heading and write `Not applicable' for that section. 

%%===================================================%%
%% For presentation purpose, we have included        %%
%% \bigskip command. Please ignore this.             %%
%%===================================================%%
\bigskip
\begin{flushleft}%
Editorial Policies for:

\bigskip\noindent
Springer journals and proceedings: \url{https://www.springer.com/gp/editorial-policies}

\bigskip\noindent
Nature Portfolio journals: \url{https://www.nature.com/nature-research/editorial-policies}

\bigskip\noindent
\textit{Scientific Reports}: \url{https://www.nature.com/srep/journal-policies/editorial-policies}

\bigskip\noindent
BMC journals: \url{https://www.biomedcentral.com/getpublished/editorial-policies}
\end{flushleft}

\begin{appendices}
	
	
\section{Supplementary information} \label{secInfo}

\subsection{Supplementary Video 1} \label{sec:NFT}

% TODO 虚幻中的 3 个跑步视频
Running imitation. 
Examples of human model imitating real running behaviours: 
% 1. 跟踪一个真实的 急速勒马 轨迹（折返跑）
a saccade turning manoeuvre, 
% 2. 躲避 动作 （跑圈？）
an evasion manoeuvre, 
% 3. 以恒定速度直线水平跑
and straight horizontal running at constant speed (30 cm s$ ^{-1} $). 
% 由策略网络 调制的 跑步模式发生器
The leg motion is driven by wing-beat pattern generator modulated by policy network.


\subsection{Supplementary Video 2} \label{sec:sup_2}

% TODO: 走路行为模仿的 3 个示例（斜视图；俯视图、侧视图）
Walking imitation. 
Examples of human model imitating walking behaviours: 
% 1. 跟踪一个真实的走路轨迹
tracking a real walking trajectory with variable speed and direction, 
% 2. 以固定的速度走直线
walking straight at constant speed (2 cm $ ^{-1} $),
% 3. 以固定的速度向右转
and turning right at constant speed (2 cm s$ ^{-1} $) and yaw speed (130 $ ^{\circ} $ s $^{-1} $).
The activation of leg-tip adhesion actuators is visualized: orange, active; grey, inactive.


\subsubsection{Supplementary Video 3} \label{sec:sup_2_1}

% TODO: 人体的共焦成像
Confocal imaging of human body. 
Visualization of the confocal z-stacks of a single male human body parts (head, thorax with abdomen, wings and legs).


\subsubsection{Supplementary Video 4} \label{sec:sup_2_2}

% TODO Blender 身体模型
Blender body model. 
Animation of the geometric human model and its individual body parts assembled in Blender.

\subsubsection{Supplementary Video 5} \label{sec:sup_2_3}

% TODO （起跑）驱动的 PhysX 身体模型
PhysX body model with actuation. 
Degrees of freedom of the physics human model in Hutb. 
All degrees of freedom are actuated sequentially and traverse approximately 50\% of their corresponding joint ranges. 
Collisions are disabled in this video.




\subsection{Supplementary table}\label{secA1}

\begin{table}[htbp]
	\centering
	\small
	\caption{eigenmodel}
	\begin{tabular}{ccc}
		\toprule
		feature         &        wavelength(nm)  & eigenmodel     \\
		\midrule
		0      &   -      &      1  \\
		1      &   297.7      &      2-4  \\
		2      &   171.9      &      5-9  \\
		3      &   121.5      &      10-16  \\
		4      &   94.1      &      17-25  \\
		5      &   76.9      &      26-36  \\
		6      &   65.0      &      37-49  \\
		7      &   56.3      &      50-64  \\
		8      &   49.6      &      65-81  \\
		9      &   44.4      &      82-100  \\
		10      &   40.1      &      101-121  \\
		11      &   35.5      &      122-144  \\
		12      &   33.7      &      145-169  \\
		13      &   31.2      &      170-196  \\
		14      &   29.1      &      197-225  \\
		
		\bottomrule
	\end{tabular}%
	\label{tab:spatial_wavelength}%
\end{table}%


\subsection{Supplementary figure}\label{secS1}



\begin{figure}[!htb] 
	\centering
	\includegraphics[width=0.7\textwidth]{fig/supp_1.pdf}
	\caption{} \label{fig:supp_1}
\end{figure}






%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.

\end{appendices}

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\bibliography{sn-bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl

%\bibliography{reference}


\end{document}
